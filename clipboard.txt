==== dataset.py ====
import os
import torch
from torch.utils.data import Dataset
from torchvision.transforms import ToTensor
import numpy as np
from PIL import Image
import glob


class InstanceSegDataset(Dataset):
    def __init__(self, root_dir, is_train=True, transforms=None):
        self.root_dir = root_dir
        self.is_train = is_train
        self.transforms = transforms or ToTensor()
        self.samples = []

        if self.is_train:
            self.samples = sorted(os.listdir(os.path.join(root_dir, 'train')))
        else:
            self.samples = sorted(glob.glob(os.path.join(root_dir, 'test', '*.tif')))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        if self.is_train:
            sample_id = self.samples[idx]
            img_path = os.path.join(self.root_dir, 'train', sample_id, 'image.tif')
            image = Image.open(img_path).convert("RGB")

            # Load all mask classes: class1.tif, class2.tif, ...
            mask_dir = os.path.join(self.root_dir, 'train', sample_id)
            masks = []
            labels = []
            for class_idx in range(1, 5):  # class1 to class4
                class_mask_path = os.path.join(mask_dir, f'class{class_idx}.tif')
                if not os.path.exists(class_mask_path):
                    continue
                class_mask = np.array(Image.open(class_mask_path))
                instance_ids = np.unique(class_mask)
                instance_ids = instance_ids[instance_ids > 0]

                for instance_id in instance_ids:
                    instance_mask = (class_mask == instance_id).astype(np.uint8)
                    masks.append(instance_mask)
                    labels.append(class_idx)

            if self.transforms:
                transformed = self.transforms(image=np.array(image), masks=masks)
                image = transformed["image"]
                masks = torch.stack([torch.tensor(m, dtype=torch.uint8) for m in transformed["masks"]])
            else:
                image = ToTensor()(image)
                masks = torch.stack([torch.tensor(m, dtype=torch.uint8) for m in masks])

            labels = torch.tensor(labels, dtype=torch.int64)
            target = {
                "masks": masks,
                "labels": labels,
            }
            return image, target

        else:
            img_path = self.samples[idx]
            image = Image.open(img_path).convert("RGB")
            image = self.transforms(image)
            image_id = os.path.basename(img_path).replace('.tif', '')
            return image, image_id\n==== train.py ====
import torch
import torchvision
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor
from src.dataset import InstanceSegDataset
from src.model import get_instance_segmentation_model
import os
from tqdm import tqdm

def collate_fn(batch):
    return tuple(zip(*batch))

def train(num_epochs=10, lr=1e-4, batch_size=2, model_save_path="model.pth"):
    # Setup device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Dataset and DataLoader
    dataset = InstanceSegDataset("hw3-data-release", is_train=True, transforms=ToTensor())
    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)

    # Model
    model = get_instance_segmentation_model(num_classes=5)
    model.to(device)

    # Optimizer and LR scheduler
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.AdamW(params, lr=lr)
    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

    # Training loop
    model.train()
    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}/{num_epochs}")
        total_loss = 0.0

        for images, targets in tqdm(data_loader):
            images = [img.to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())

            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

            total_loss += losses.item()

        lr_scheduler.step()
        print(f"Epoch {epoch+1} Loss: {total_loss:.4f}")

        # Save model
        torch.save(model.state_dict(), model_save_path)
        print(f"Model saved to {model_save_path}")


if __name__ == "__main__":
    train()\n==== transforms.py ====
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np

def get_train_transform():
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.3),
        A.RandomRotate90(p=0.5),
        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),
        A.OneOf([
            A.ElasticTransform(p=0.3, alpha=1, sigma=50, alpha_affine=30),
            A.GridDistortion(p=0.3),
        ], p=0.4),
        A.RandomBrightnessContrast(p=0.3),
        A.GaussianBlur(p=0.1),
        A.GaussNoise(p=0.1),
        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
        ToTensorV2()
    ])

def get_val_transform():
    return A.Compose([
        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
        ToTensorV2()
    ])\n==== model.py ====
import torchvision
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor

def get_instance_segmentation_model(num_classes=5):
    # Load pre-trained model
    model = maskrcnn_resnet50_fpn(pretrained=True)

    # Replace the box predictor
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    # Replace the mask predictor
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256
    model.roi_heads.mask_predictor = MaskRCNNPredictor(
        in_features_mask, hidden_layer, num_classes
    )

    return model